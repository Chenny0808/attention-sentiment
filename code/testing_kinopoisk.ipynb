{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cPickle\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_train = pd.read_csv('../data/kinopoisk_train.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n      Прежде чем вообще что-то говорить, нуж...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nНа мой взгляд, любой боевик должен быть стил...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nОб этом фильме мне довелось слышать не один ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nОчень сложно вспомнить фильм, в котором не б...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nВ фильме показан нетрадиционный Шерлок Холмс...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  \\n      Прежде чем вообще что-то говорить, нуж...      1\n",
       "1  \\nНа мой взгляд, любой боевик должен быть стил...      1\n",
       "2  \\nОб этом фильме мне довелось слышать не один ...      1\n",
       "3  \\nОчень сложно вспомнить фильм, в котором не б...      0\n",
       "4  \\nВ фильме показан нетрадиционный Шерлок Холмс...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts, labels = review_train.text.values, review_train.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading vocabulary and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2id, embeddings = cPickle.load(open('../data/w2v/vectors_l.pkl', 'rb'))\n",
    "# word2id, embeddings = cPickle.load(open('../data/w2v/parkin_vectors.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "word2id[u'</s>'] = embeddings.shape[0]\n",
    "embeddings = np.concatenate((embeddings, np.zeros((1, embeddings.shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = word2id.keys()\n",
    "eos_id = word2id[u'</s>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing and replacing words with ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Мне странно, что отзывы о таком шедевре настолько холодные… Такое впечатление что тут открыли форум критиков «ВК»… \n",
      "\n",
      "Фильм поражает своей масштабностью, красотой и глубиной образов и самого мира — до сих пор удивляюсь, как мог один человек создать целый мир, целую эпоху со своими мифами, героями, географией, летоисчеслением, прошлым, настояшим и будующим! \n",
      "\n",
      "Гений Толкиена идеально перенесен на большие экраны и экранизация романа просто разрывает тебя на куски! Когда смотришь фильм — ты попадаешь в сказку… причем не добрую и поучительную, а реалистичную и жесткую, где высоко приподнесены такие извечные ценности как честь, достоинство, отвага, долг. \n",
      "\n",
      "А музыка фильма это отдельный разговор! Музыкальная тема фильма выше всяких похвал — ну как могут не тронуть сердце эльфийские баллады или героические мотивы на фоне батальных сцен!\n",
      "\n",
      "Бесспорно каждый Оскар из 11 полученных взят заслужено!\n",
      "\n",
      "10 из 10\n",
      "Мне странно что отзывы о таком шедевре настолько холодные Такое впечатление что тут открыли форум критиков ВК Фильм поражает своей масштабностью красотой и глубиной образов и самого мира до сих пор удивляюсь как мог один человек создать целый мир целую эпоху со своими мифами героями географией летоисчеслением прошлым настояшим и будующим Гений Толкиена идеально перенесен на большие экраны и экранизация романа просто разрывает тебя на куски Когда смотришь фильм ты попадаешь в сказку причем не добрую и поучительную а реалистичную и жесткую где высоко приподнесены такие извечные ценности как честь достоинство отвага долг А музыка фильма это отдельный разговор Музыкальная тема фильма выше всяких похвал ну как могут не тронуть сердце эльфийские баллады или героические мотивы на фоне батальных сцен Бесспорно каждый Оскар из полученных взят заслужено из\n",
      "я странно что отзыв о такой шедевр настолько холодное такой впечатление что тут открыть форум критик вк фильм поражать свой масштабность красота и глубина образ и самый мир до сей пора удивляться как мочь один человек создать целый мир целовать эпоха с свой миф герой география летоисчесление прошлое настояшим и будуть гений толкиен идеально перенести на большой экран и экранизация роман просто разрывать ты на кусок когда смотреть фильм ты попадать в сказка причём не добрый и поучительный а реалистичный и жёсткий где высоко приподнести такой извечный ценность как честь достоинство отвага долг а музыка фильм это отдельный разговор музыкальный тема фильм выше всякий похвала ну как мочь не тронуть сердце эльфийский баллада или героический мотив на фон батальный сцена бесспорный каждый оскар из получить взять заслужить из\n",
      "[10, 1031, 4, 5094, 26, 30, 4824, 1204, 5839, 30, 1363, 4, 95, 1041, 1765, 7446, 4095, 335, 4580, 24, 34095, 2032, 1, 3754, 415, 1, 69, 98, 61, 477, 205, 1794, 14, 40, 39, 27, 384, 1591, 98, 3611, 2214, 8, 24, 2500, 506, 5537, 91114, 595, 1, 13035, 3172, 30321, 8061, 4107, 5, 68, 2671, 1, 18233, 698, 62, 11241, 28, 5, 1776, 59, 155, 335, 28, 2321, 2, 1348, 305, 3, 488, 1, 13554, 6, 15146, 1, 1777, 82, 6202, 49609, 30, 14186, 873, 14, 1107, 2079, 13510, 683, 6, 1533, 335, 7, 945, 805, 4613, 270, 335, 560, 341, 12579, 54, 14, 40, 3, 7011, 1210, 51803, 23289, 46, 6168, 3082, 5, 1378, 43807, 2375, 7376, 130, 6843, 31, 198, 218, 2196, 31, 0]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pymorphy2\n",
    "\n",
    "tokenizer = RegexpTokenizer(u'[а-яА-Яa-zA-Z]+')\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def text2seq(text):\n",
    "    tokens_norm = [morph.parse(w)[0].normal_form for w in tokenizer.tokenize(text)]\n",
    "    return [word2id[w] for w in tokens_norm if w in vocabulary] + [eos_id]\n",
    "\n",
    "sample = texts[49]\n",
    "\n",
    "print sample\n",
    "print u' '.join(tokenizer.tokenize(sample))\n",
    "print u' '.join([morph.parse(w)[0].normal_form for w in tokenizer.tokenize(sample)])\n",
    "print text2seq(sample)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TODO: adding new words to vocabulary\n",
    "from fuzzywuzzy import fuzz\n",
    "metric = fuzz.ratio\n",
    "if word not in vocabulary:        \n",
    "    max_score = 0\n",
    "    closest_word = vocabulary[0]\n",
    "    for w in vocabulary:\n",
    "        score = metric(word, w)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            closest_word = w\n",
    "    ..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "pool = multiprocessing.Pool()\n",
    "X = pool.map(text2seq, texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dumping"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "cPickle.dump(X, open('../data/X_review_train.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = cPickle.load(open('../data/X_kinopoisk_train.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop samples with the length > 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_max = 1024\n",
    "y = review_train.label.values\n",
    "y = y[np.array(map(len, X)) < length_max]\n",
    "X = [x for x in X if len(x) < length_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [x + [eos_id]*(length_max - len(x)) for x in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[799, 64, 102, 4, 12, 73, 137, 2096, 281, 67, 736, 2359, 4, 7, 663, 31, 57, 94, 139, 11, 51, 8137, 281, 506, 10224, 1, 9144, 8137, 16, 6134, 605, 113, 3, 2, 1330, 506, 14, 1236, 4, 80, 12, 1, 198, 36, 48, 31095, 1, 8400, 6981, 6, 47766, 4082, 2, 1714, 12, 103, 20511, 3, 9, 2205, 15693, 15, 3, 478, 644, 64, 8400, 17, 131, 46, 47766, 11199, 140, 2205, 8687, 3, 565, 71, 39, 31, 178, 506, 6, 26, 50, 8687, 78, 73, 36, 16, 1600, 9748, 5, 2375, 1, 60, 2, 39, 485, 135, 1416, 1403, 6888, 9294, 5, 4, 9294, 5, 30, 38, 4740, 335, 33, 67, 17, 57, 1, 49, 9294, 4, 38, 561, 9294, 5, 9294, 7, 48, 3, 2, 50, 1330, 45, 1, 14, 65, 61240, 1525, 2, 30, 5352, 50, 244, 69, 65, 335, 26177, 15630, 24, 4619, 263, 17, 88, 192, 76, 170, 191, 9, 256, 4, 12, 6401, 8, 69, 368, 9, 732, 29, 1394, 43, 3743, 2, 8882, 427, 109, 2345, 5, 39, 89, 40, 123, 4, 10, 3, 256, 107, 5068, 182, 1, 910, 6, 4211, 78, 1, 281, 1223, 36, 76, 344, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cls2probs(cls):\n",
    "    if cls == -1:\n",
    "        return [1.,0., 0.]\n",
    "    if cls == 0:\n",
    "        return [0.,1., 0.]\n",
    "    else:\n",
    "        return [0.,0.,1.]\n",
    "y = np.array([cls2probs(cls) for cls in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=40)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# To use if y is one-dimensional array\n",
    "from collections import Counter\n",
    "\n",
    "print Counter(y_tr)\n",
    "print Counter(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class frequencies:\t[3385, 3237, 19514]\n",
      "Validation class frequencies:\t[367, 387, 2151]\n",
      "Constant classifier's validation accuracy:\t0.740447504303\n"
     ]
    }
   ],
   "source": [
    "print \"Train class frequencies:\\t\", [col.nonzero()[0].shape[0] for col in y_tr.transpose()]\n",
    "print \"Validation class frequencies:\\t\", [col.nonzero()[0].shape[0] for col in y_val.transpose()]\n",
    "print \"Constant classifier's validation accuracy:\\t\", [col.nonzero()[0].shape[0] for col in y_val.transpose()][2] * 1. / y_val.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# rus = RandomUnderSampler()\n",
    "# _y = np.argmax(y_tr, 1) - 1\n",
    "# X_resampled, y_resampled = rus.fit_sample(X_tr, _y)\n",
    "# y_resampled = np.array([cls2probs(cls) for cls in y_resampled])\n",
    "\n",
    "neutral_indices = np.random.choice(np.nonzero(y_tr[:,1])[0], np.nonzero(y_tr[:,0])[0].shape[0], replace=False)\n",
    "negative_indices = np.nonzero(y_tr[:,0])[0]\n",
    "positive_indices = np.nonzero(y_tr[:,2])[0]\n",
    "\n",
    "X_resampled = X_tr[np.concatenate([negative_indices, neutral_indices, positive_indices])]\n",
    "y_resampled = y_tr[np.concatenate([negative_indices, neutral_indices, positive_indices])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn import GRUCell\n",
    "from tensorflow.python.ops.rnn import bidirectional_dynamic_rnn as bi_rnn\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant classifier's macro-averaged F-score on validation set: 0.283623417722\n",
      "Constant classifier's micro-averaged F-score on validation set: 0.740447504303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f_macro = lambda y1, y2: f1_score(y1, y2, average=\"macro\")\n",
    "f_micro = lambda y1, y2: f1_score(y1, y2, average=\"micro\")\n",
    "\n",
    "y_pred_major = np.zeros(y_val.shape)\n",
    "y_pred_major[:,2] = 1.\n",
    "print \"Constant classifier's macro-averaged F-score on validation set:\", f_macro(y_val, y_pred_major)\n",
    "print \"Constant classifier's micro-averaged F-score on validation set:\", f_micro(y_val, y_pred_major)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-RNN with Attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention mechanism formulas and notation\n",
    "$$\n",
    "\\upsilon_{t}=\\tanh{(W_{\\omega}\\left[\\overrightarrow{h_{t}},\\overleftarrow{h_{t}}\\right]+b_{\\omega})}\\\\\n",
    "\\alpha_{t}=\\frac{\\exp{(\\upsilon_{t}^{T}u_{\\omega})}}{\\sum_{j=1}^{T}\\exp{(\\upsilon_{j}^{T}u_{\\omega})}}\\\\\n",
    "\\upsilon=\\sum_{t=1}^{T}\\alpha_{t}h_{t}\t\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBED_DIM = 300\n",
    "SEQ_LENGTH = length_max\n",
    "HIDDEN_SIZE = 64\n",
    "ATTENTION_SIZE = 32\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "batch_ph   = tf.placeholder(tf.int32, [None, SEQ_LENGTH])\n",
    "target_ph  = tf.placeholder(tf.float32, [None, NUM_CLASSES])\n",
    "seq_len_ph = tf.placeholder(tf.int32, [None])\n",
    "keep_prob_ph = tf.placeholder(tf.float32)\n",
    "\n",
    "embeddings_ph = tf.placeholder(tf.float32, [len(vocabulary), EMBED_DIM])\n",
    "embeddings_var = tf.Variable(tf.constant(0., shape=[len(vocabulary), EMBED_DIM]), trainable=False)\n",
    "init_embeddings = embeddings_var.assign(embeddings_ph)\n",
    "\n",
    "batch_embedded = tf.nn.embedding_lookup(embeddings_var, batch_ph)\n",
    "\n",
    "# Bi-RNN layers\n",
    "outputs,_ = bi_rnn(GRUCell(HIDDEN_SIZE), GRUCell(HIDDEN_SIZE),\n",
    "                   inputs=batch_embedded,sequence_length=seq_len_ph, dtype=tf.float32, scope=\"bi_rnn1\")  \n",
    "outputs = tf.concat(outputs, 2)\n",
    "# outputs,_ = bi_rnn(GRUCell(HIDDEN_SIZE), GRUCell(HIDDEN_SIZE),\n",
    "#                          inputs=outputs,sequence_length=seq_len_ph, dtype=tf.float32, scope=\"bi_rnn2\")\n",
    "# outputs = tf.concat(outputs, 2)\n",
    "\n",
    "# Attention mechanism\n",
    "W_omega = tf.Variable(tf.random_normal([2 * HIDDEN_SIZE, ATTENTION_SIZE], stddev=0.1))\n",
    "b_omega = tf.Variable(tf.random_normal([ATTENTION_SIZE], stddev=0.1))\n",
    "u_omega = tf.Variable(tf.random_normal([ATTENTION_SIZE], stddev=0.1))\n",
    "\n",
    "v = tf.tanh(tf.matmul(tf.reshape(outputs, [-1, 2 * HIDDEN_SIZE]), W_omega) + tf.reshape(b_omega, [1, -1]))\n",
    "vu = tf.matmul(v, tf.reshape(u_omega, [-1, 1]))\n",
    "exps = tf.reshape(tf.exp(vu), [-1, SEQ_LENGTH])\n",
    "alphas = exps / tf.reshape(tf.reduce_sum(exps, 1), [-1, 1])\n",
    "\n",
    "# Output of Bi-RNN reduced with attention vector\n",
    "output = tf.reduce_sum(outputs * tf.reshape(alphas, [-1, SEQ_LENGTH, 1]), 1)\n",
    "\n",
    "# Dropout\n",
    "drop = tf.nn.dropout(output, keep_prob_ph)\n",
    "\n",
    "# Fully connected layer\n",
    "W = tf.Variable(tf.truncated_normal([HIDDEN_SIZE * 2, NUM_CLASSES], stddev=0.1), name=\"W\")\n",
    "b = tf.Variable(tf.constant(0., shape=[NUM_CLASSES]), name=\"b\")\n",
    "y_hat = tf.nn.xw_plus_b(drop, W, b, name=\"scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adam parameters\n",
    "LEARNING_RATE = 0.008\n",
    "EPSILON = 1e-5\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.9\n",
    "# L2 regularization coefficient\n",
    "BETA = 0\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=target_ph, logits=y_hat), name=\"cross_entropy\")\n",
    "l2_loss = tf.nn.l2_loss(W, name=\"l2_loss\")\n",
    "loss = cross_entropy + l2_loss * BETA\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE, beta1=BETA1, beta2=BETA2,\n",
    "                                   epsilon=EPSILON).minimize(loss)\n",
    "# optimizer = tf.train.AdadeltaOptimizer(learning_rate=LEARNING_RATE, rho=0.7).minimize(loss)\n",
    "# optimizer = tf.train.AdagradOptimizer(learning_rate=LEARNING_RATE, initial_accumulator_value=0.1).minimize(loss)\n",
    "# optimizer = tf.train.MomentumOptimizer(learning_rate=LEARNING_RATE, momentum=0.1).minimize(loss)\n",
    "# optimizer = tf.train.RMSPropOptimizer(learning_rate=LEARNING_RATE, decay=0.9, momentum=0.1).minimize(loss)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(target_ph, 1), tf.argmax(y_hat, 1)), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start learning...-f\n",
      "epoch: 0\n",
      "\t Train loss: 0.568\t ce: 0.568\t acc: 0.773\t f_macro: 0.490\n",
      "\t Valid loss: 0.502\t ce: 0.502\t acc: 0.809\t f_macro: 0.521\n",
      "epoch: 1\n",
      "\t Train loss: 0.508\t ce: 0.508\t acc: 0.812\t f_macro: 0.583\n",
      "\t Valid loss: 0.450\t ce: 0.450\t acc: 0.825\t f_macro: 0.600\n",
      "epoch: 2\n",
      "\t Train loss: 0.408\t ce: 0.408\t acc: 0.836\t f_macro: 0.605\n",
      "\t Valid loss: 0.447\t ce: 0.447\t acc: 0.829\t f_macro: 0.586\n",
      "epoch: 3\n",
      "\t Train loss: 0.445\t ce: 0.445\t acc: 0.828\t f_macro: 0.636\n",
      "\t Valid loss: 0.425\t ce: 0.425\t acc: 0.837\t f_macro: 0.633\n",
      "epoch: 4\n",
      "\t Train loss: 0.439\t ce: 0.439\t acc: 0.832\t f_macro: 0.577\n",
      "\t Valid loss: 0.444\t ce: 0.444\t acc: 0.836\t f_macro: 0.600\n",
      "epoch: 5\n",
      "\t Train loss: 0.338\t ce: 0.338\t acc: 0.848\t f_macro: 0.653\n",
      "\t Valid loss: 0.437\t ce: 0.437\t acc: 0.836\t f_macro: 0.658\n",
      "epoch: 6\n",
      "\t Train loss: 0.285\t ce: 0.285\t acc: 0.891\t f_macro: 0.736\n",
      "\t Valid loss: 0.473\t ce: 0.473\t acc: 0.836\t f_macro: 0.639\n",
      "epoch: 7\n",
      "\t Train loss: 0.244\t ce: 0.244\t acc: 0.902\t f_macro: 0.796\n",
      "\t Valid loss: 0.501\t ce: 0.501\t acc: 0.835\t f_macro: 0.675\n",
      "epoch: 8\n",
      "\t Train loss: 0.148\t ce: 0.148\t acc: 0.938\t f_macro: 0.870\n",
      "\t Valid loss: 0.558\t ce: 0.558\t acc: 0.825\t f_macro: 0.668\n",
      "epoch: 9\n",
      "\t Train loss: 0.148\t ce: 0.148\t acc: 0.941\t f_macro: 0.891\n",
      "\t Valid loss: 0.682\t ce: 0.682\t acc: 0.822\t f_macro: 0.657\n"
     ]
    }
   ],
   "source": [
    "DROPOUT = 0.8  # Probability of keeping a neuron\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 10\n",
    "\n",
    "train_batch_generator = batch_generator(X_tr, y_tr, BATCH_SIZE)\n",
    "\n",
    "loss_tr_l = []\n",
    "loss_val_l = []\n",
    "ce_tr_l = []  # Cross-entropy\n",
    "ce_val_l = []\n",
    "acc_tr_l = []  # Accuracy\n",
    "acc_val_l = []\n",
    "f_macro_tr_l = []\n",
    "f_macro_val_l = []\n",
    "f_fair_tr_l = []\n",
    "f_fair_val_l = []\n",
    "max_val_f = 0.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(init_embeddings, feed_dict={embeddings_ph: embeddings})\n",
    "    print \"Start learning...\"\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in range(int(X_tr.shape[0] / BATCH_SIZE)):\n",
    "            x_batch, y_batch = train_batch_generator.next()\n",
    "            seq_len_tr = np.array([list(x).index(eos_id) + 1 for x in x_batch])\n",
    "            sess.run(optimizer, feed_dict={batch_ph: x_batch, target_ph: y_batch,\n",
    "                                           seq_len_ph: seq_len_tr, keep_prob_ph: DROPOUT})\n",
    "\n",
    "        y_pred_tr, ce_tr, loss_tr, acc_tr = sess.run([y_hat, cross_entropy, loss, accuracy],\n",
    "                                                     feed_dict={batch_ph: x_batch, target_ph: y_batch,\n",
    "                                                                seq_len_ph: seq_len_tr, keep_prob_ph: 1.0})\n",
    "\n",
    "        y_pred_val, ce_val, loss_val, acc_val = [], 0, 0, 0\n",
    "        num_val_batches = X_val.shape[0] / BATCH_SIZE\n",
    "        for i in range(num_val_batches):\n",
    "            x_batch_val, y_batch_val = X_val[i * BATCH_SIZE: (i + 1) * BATCH_SIZE], y_val[i * BATCH_SIZE: (\n",
    "                                                                                                              i + 1) * BATCH_SIZE]\n",
    "            seq_len_val = np.array([list(x).index(eos_id) + 1 for x in x_batch_val])\n",
    "            y_pred_val_, ce_val_, loss_val_, acc_val_ = sess.run([y_hat, cross_entropy, loss, accuracy],\n",
    "                                                                 feed_dict={batch_ph: x_batch_val,\n",
    "                                                                            target_ph: y_batch_val,\n",
    "                                                                            seq_len_ph: seq_len_val,\n",
    "                                                                            keep_prob_ph: 1.0})\n",
    "            y_pred_val += list(y_pred_val_)\n",
    "            ce_val += ce_val_\n",
    "            loss_val += loss_val_\n",
    "            acc_val += acc_val_\n",
    "\n",
    "        y_pred_val = np.array(y_pred_val)\n",
    "        ce_val /= num_val_batches\n",
    "        loss_val /= num_val_batches\n",
    "        acc_val /= num_val_batches\n",
    "\n",
    "        y_pred_tr = np.array([cls2probs(cls) for cls in np.argmax(y_pred_tr, 1) - 1])\n",
    "        y_pred_val = np.array([cls2probs(cls) for cls in np.argmax(y_pred_val, 1) - 1])\n",
    "        f_macro_tr, f_micro_tr = f_macro(y_batch, y_pred_tr), f_micro(y_batch, y_pred_tr)\n",
    "        f_macro_val, f_micro_val = f_macro(y_val[:num_val_batches * BATCH_SIZE], y_pred_val), f_micro(\n",
    "            y_val[:num_val_batches * BATCH_SIZE], y_pred_val)\n",
    "\n",
    "        loss_tr_l.append(loss_tr)\n",
    "        loss_val_l.append(loss_val)\n",
    "        ce_tr_l.append(ce_tr)\n",
    "        ce_val_l.append(ce_val)\n",
    "        acc_tr_l.append(acc_tr)\n",
    "        acc_val_l.append(acc_val)\n",
    "        f_macro_tr_l.append(f_macro_tr)\n",
    "        f_macro_val_l.append(f_macro_val)\n",
    "\n",
    "        print \"epoch: {}\".format(epoch)\n",
    "        print \"\\t Train loss: {:.3f}\\t ce: {:.3f}\\t acc: {:.3f}\\t f_macro: {:.3f}\".format(\n",
    "            loss_tr, ce_tr, acc_tr, f_macro_tr)\n",
    "        print \"\\t Valid loss: {:.3f}\\t ce: {:.3f}\\t acc: {:.3f}\\t f_macro: {:.3f}\".format(\n",
    "            loss_val, ce_val, acc_val, f_macro_val)\n",
    "\n",
    "        if f_macro_val > max_val_f:\n",
    "            max_val_f = f_macro_val\n",
    "            saver.save(sess, 'model')\n",
    "\n",
    "    results = [max(acc_val_l), max(f_macro_val_l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.83700284090909094, 0.67486937331503383]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_test = pd.read_csv('../data/kinopoisk_test.csv', sep=',', encoding='utf-8')\n",
    "texts_test, labels_test = review_test.text.values, review_test.label.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "pool = multiprocessing.Pool()\n",
    "X_test = pool.map(text2seq, texts_test)\n",
    "cPickle.dump(X_test, open('../data/X_reviews_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = cPickle.load(open('../data/X_kinopoisk_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = [x[:length_max - 1] for x in X_test]\n",
    "X_test = [x + [eos_id]*(length_max - len(x)) for x in X_test]\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array([cls2probs(cls) for cls in labels_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7270, 1024), (7270, 3))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant classifier's test accuracy:\t0.735763411279\n",
      "Constant classifier's macro-averaged F-score on validation set: 0.282589745622\n"
     ]
    }
   ],
   "source": [
    "print \"Constant classifier's test accuracy:\\t\", [col.nonzero()[0].shape[0] for col in y_test.transpose()][2] * 1. / y_test.shape[0]\n",
    "y_pred_major = np.zeros(y_test.shape)\n",
    "y_pred_major[:,2] = 1.\n",
    "print \"Constant classifier's macro-averaged F-score on validation set:\", f_macro(y_test, y_pred_major)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph('model.meta')\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "\n",
    "    y_pred_test, ce_test, loss_test, acc_test = [], 0, 0, 0\n",
    "    num_test_batches = X_test.shape[0] / BATCH_SIZE\n",
    "    for i in range(num_test_batches):\n",
    "        x_batch_test, y_batch_test = X_test[i * BATCH_SIZE : (i + 1) * BATCH_SIZE],\\\n",
    "                                   y_test[i * BATCH_SIZE : (i + 1) * BATCH_SIZE]\n",
    "        seq_len_test = np.array([list(x).index(eos_id) + 1 for x in x_batch_test])\n",
    "        y_pred_test_, ce_test_, loss_test_, acc_test_ = sess.run([y_hat, cross_entropy, loss, accuracy],\n",
    "                                                     feed_dict={batch_ph: x_batch_test, target_ph: y_batch_test,\n",
    "                                                                seq_len_ph: seq_len_test, keep_prob_ph: 1.0})\n",
    "        y_pred_test += list(y_pred_test_)\n",
    "        ce_test += ce_test_\n",
    "        loss_test += loss_test_\n",
    "        acc_test += acc_test_\n",
    "\n",
    "    y_pred_test = np.array(y_pred_test)\n",
    "    ce_test /= num_test_batches\n",
    "    loss_test /= num_test_batches\n",
    "    acc_test /= num_test_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811941964286 0.637816372677\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = np.array([cls2probs(cls) for cls in np.argmax(y_pred_test, 1) - 1])\n",
    "f_macro_test = f_macro(y_test[:num_test_batches * BATCH_SIZE], y_pred_test)\n",
    "print acc_test, f_macro_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2word = {}\n",
    "for word, word_id in word2id.iteritems():\n",
    "    id2word[word_id] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Нолан — мой любимый режиссер. А его «Помни» — мой любимый фильм. Но только сейчас я с удивлением узнала, что «Престиж» снял тот же режиссер. Собственно, сам фильм я посмотрела не из-за громких имен актеров и режиссера, а потому, что прочитала книгу. Произведение Кристофера Приста словно схватило меня за душу и не отпускало до самого конца. А вечером я пересказывала историю двух иллюзионистов своей подруге, которая понимала меня с трудом, ведь сам сюжет настолько лихо закручен, а конец просто шедеврален! И на этой позитивной ноте я взялась за фильм. Скажу честно — разочаровал. Скучнее я ничего не видела. После нескольких первых минут я начала «пропадать» в сюжете. Он оказался уж больно запутанным, да так, что, кажется, сценарист сам в нем запутался с режиссером на пару. Всё время пыталась связать происходящее на экране с книгой, но, как ни старалась, ничего общего не нашла. Вкуснейшая интрига Приста была отвратительно чем-то разбавлена. Блюдо остыло и дорога ему на помойку. Единственное, что хоть немного меня порадовало, так это актерский состав. Игра потрясающая, но со Скарлетт что-то было не так. Возможно, дело в самой Оливии. Кажется, в книге этот персонаж был полнее. \n",
      "\n",
      "В общем, в попытке переделать роман на большой экран, была уничтожена вся острота начинки. Для меня, это — худшая экранизация прочитанной книги.\n",
      "\n",
      "Вот так вот,\n",
      "\n",
      "3/10\n"
     ]
    }
   ],
   "source": [
    "print review_test.text.values[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sent = review_test.text.values[22]\n",
    "# print sent\n",
    "sent = \"\"\"Нолан— мой любимый режиссер. А его «Помни»— мой любимый фильм. Но только сейчас я с удивлением узнала, что «Престиж» снял тот же режиссер. Собственно, сам фильм я посмотрела не из -за громких имен актеров и режиссера, а потому, что прочитала книгу. Произведение Кристофера Приста словно схватило меня за душу и не отпускало до самого конца. А вечером я пересказывала историю двух иллюзионистов своей подруге, которая понимала меня с трудом, ведь сам сюжет настолько лихо закручен, а конец просто шедеврален! И на этой позитивной ноте я взялась за фильм. Скажу честно— разочаровал. Скучнее я ничего не видела. После нескольких первых минут я начала «пропадать» в сюжете. Он оказался уж больно запутанным, да так, что, кажется, сценарист сам в нем запутался с режиссером на пару. Всё время пыталась связать происходящее на экране с книгой, но, как ни старалась, ничего общего не нашла. Вкуснейшая интрига Приста была отвратительно чем- то разбавлена. Блюдо остыло и дорога ему на помойку. Единственное, что хоть немного меня порадовало, так это актерский состав. Игра потрясающая, но со Скарлетт что- то было не так. Возможно, дело в самой Оливии. Кажется, в книге этот персонаж был полнее. \n",
    "\n",
    "В общем, в попытке переделать роман на большой экран, была уничтожена вся острота начинки. Для меня, это— худшая экранизация прочитанной книги.\n",
    "\n",
    "Вот так вот,\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Нола— нолана\n",
      "1 мой мой\n",
      "2 любимый любимый\n",
      "3 режиссер. режиссёр\n",
      "4 А а\n",
      "5 его он\n",
      "6 «Помни»— помнить\n",
      "7 мой мой\n",
      "8 любимый любимый\n",
      "9 фильм. фильм\n",
      "10 Но но\n",
      "11 только только\n",
      "12 сейчас сейчас\n",
      "13 я я\n",
      "14 с с\n",
      "15 удивлением удивление\n",
      "16 узнала, узнать\n",
      "17 что что\n",
      "18 «Престиж» престиж\n",
      "19 снял снять\n",
      "20 тот тот\n",
      "21 же же\n",
      "22 режиссер. режиссёр\n",
      "23 Собственно, собственно\n",
      "24 сам сам\n",
      "25 фильм фильм\n",
      "26 я я\n",
      "27 посмотрела посмотреть\n",
      "28 не не\n",
      "29 из из\n",
      "30 -за за\n",
      "31 громких громкий\n",
      "32 имен имя\n",
      "33 актеров актёр\n",
      "34 и и\n",
      "35 режиссера, режиссёр\n",
      "36 а а\n",
      "37 потому, потому\n",
      "38 что что\n",
      "39 прочитала прочитать\n",
      "40 книгу. книга\n",
      "41 Произведение произведение\n",
      "42 Кристофера кристофер\n",
      "43 Приста пристый\n",
      "44 словно словно\n",
      "45 схватило схватить\n",
      "46 меня я\n",
      "47 за за\n",
      "48 душу душить\n",
      "49 и и\n",
      "50 не не\n",
      "51 отпускало отпускать\n",
      "52 до до\n",
      "53 самого самый\n",
      "54 конца. конец\n",
      "55 А а\n",
      "56 вечером вечером\n",
      "57 я я\n",
      "58 пересказывала пересказывать\n",
      "59 историю история\n",
      "60 двух два\n",
      "61 иллюзионистов иллюзионист\n",
      "62 своей свой\n",
      "63 подруге, подруга\n",
      "64 которая который\n",
      "65 понимала понимать\n",
      "66 меня я\n",
      "67 с с\n",
      "68 трудом, труд\n",
      "69 ведь ведь\n",
      "70 сам сам\n",
      "71 сюжет сюжет\n",
      "72 настолько настолько\n",
      "73 лихо лихо\n",
      "74 закручен, закрутить\n",
      "75 а а\n",
      "76 конец конец\n",
      "77 просто просто\n",
      "78 шедеврален! шедевральный\n",
      "79 И и\n",
      "80 на на\n",
      "81 этой этот\n",
      "82 позитивной позитивный\n",
      "83 ноте нота\n",
      "84 я я\n",
      "85 взялась взяться\n",
      "86 за за\n",
      "87 фильм. фильм\n",
      "88 Скажу сказать\n",
      "89 честно— честно\n",
      "90 разочаровал. разочаровать\n",
      "91 Скучнее скучный\n",
      "92 я я\n",
      "93 ничего ничто\n",
      "94 не не\n",
      "95 видела. видеть\n",
      "96 После после\n",
      "97 нескольких несколько\n",
      "98 первых один\n",
      "99 минут минута\n",
      "100 я я\n",
      "101 начала начало\n",
      "102 «пропадать» пропадать\n",
      "103 в в\n",
      "104 сюжете. сюжет\n",
      "105 Он он\n",
      "106 оказался оказаться\n",
      "107 уж уж\n",
      "108 больно больно\n",
      "109 запутанным, запутанный\n",
      "110 да да\n",
      "111 так, так\n",
      "112 что, что\n",
      "113 кажется, кажется\n",
      "114 сценарист сценарист\n",
      "115 сам сам\n",
      "116 в в\n",
      "117 нем немой\n",
      "118 запутался запутаться\n",
      "119 с с\n",
      "120 режиссером режиссёр\n",
      "121 на на\n",
      "122 пару. пара\n",
      "123 Всё вс\n",
      "124 время время\n",
      "125 пыталась пытаться\n",
      "126 связать связать\n",
      "127 происходящее происходить\n",
      "128 на на\n",
      "129 экране экран\n",
      "130 с с\n",
      "131 книгой, книга\n",
      "132 но, но\n",
      "133 как как\n",
      "134 ни ни\n",
      "135 старалась, стараться\n",
      "136 ничего ничто\n",
      "137 общего общий\n",
      "138 не не\n",
      "139 нашла. найти\n",
      "140 Вкуснейшая вкусный\n",
      "141 интрига интрига\n",
      "142 Приста пристый\n",
      "143 была быть\n",
      "144 отвратительно отвратительный\n",
      "145 чем- чем\n",
      "146 то то\n",
      "147 разбавлена. разбавить\n",
      "148 Блюдо блюдо\n",
      "149 остыло остылый\n",
      "150 и и\n",
      "151 дорога дорога\n",
      "152 ему он\n",
      "153 на на\n",
      "154 помойку. помойка\n",
      "155 Единственное, единственный\n",
      "156 что что\n",
      "157 хоть хоть\n",
      "158 немного немного\n",
      "159 меня я\n",
      "160 порадовало, порадовать\n",
      "161 так так\n",
      "162 это это\n",
      "163 актерский актёрский\n",
      "164 состав. состав\n",
      "165 Игра игра\n",
      "166 потрясающая, потрясать\n",
      "167 но но\n",
      "168 со с\n",
      "169 Скарлетт скарлетта\n",
      "170 что- что\n",
      "171 то то\n",
      "172 было быть\n",
      "173 не не\n",
      "174 так. так\n",
      "175 Возможно, возможно\n",
      "176 дело дело\n",
      "177 в в\n",
      "178 самой самый\n",
      "179 Оливии. оливия\n",
      "180 Кажется, кажется\n",
      "181 в в\n",
      "182 книге книга\n",
      "183 этот этот\n",
      "184 персонаж персонаж\n",
      "185 был быть\n",
      "186 полнее. полный\n",
      "187 В в\n",
      "188 общем, общий\n",
      "189 в в\n",
      "190 попытке попытка\n",
      "191 переделать переделать\n",
      "192 роман роман\n",
      "193 на на\n",
      "194 большой большой\n",
      "195 экран, экран\n",
      "196 была быть\n",
      "197 уничтожена уничтожить\n",
      "198 вся весь\n",
      "199 острота острота\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for q, r in zip(sent.split(), map(id2word.get, X_test[22][:200])):\n",
    "    print i, q, r\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\colorbox{yellow!4}{Нола—}\n",
      "\\colorbox{yellow!6}{мой}\n",
      "\\colorbox{yellow!6}{любимый}\n",
      "\\colorbox{yellow!8}{режиссер.}\n",
      "\\colorbox{yellow!3}{А}\n",
      "\\colorbox{yellow!4}{его}\n",
      "\\colorbox{yellow!3}{«Помни»—}\n",
      "\\colorbox{yellow!4}{мой}\n",
      "\\colorbox{yellow!4}{любимый}\n",
      "\\colorbox{yellow!4}{фильм.}\n",
      "\\colorbox{yellow!2}{Но}\n",
      "\\colorbox{yellow!1}{только}\n",
      "\\colorbox{yellow!0}{сейчас}\n",
      "\\colorbox{yellow!0}{я}\n",
      "\\colorbox{yellow!1}{с}\n",
      "\\colorbox{yellow!3}{удивлением}\n",
      "\\colorbox{yellow!2}{узнала,}\n",
      "\\colorbox{yellow!2}{что}\n",
      "\\colorbox{yellow!4}{«Престиж»}\n",
      "\\colorbox{yellow!1}{снял}\n",
      "\\colorbox{yellow!2}{тот}\n",
      "\\colorbox{yellow!2}{же}\n",
      "\\colorbox{yellow!7}{режиссер.}\n",
      "\\colorbox{yellow!5}{Собственно,}\n",
      "\\colorbox{yellow!6}{сам}\n",
      "\\colorbox{yellow!11}{фильм}\n",
      "\\colorbox{yellow!2}{я}\n",
      "\\colorbox{yellow!0}{посмотрела}\n",
      "\\colorbox{yellow!2}{не}\n",
      "\\colorbox{yellow!2}{из}\n",
      "\\colorbox{yellow!4}{-за}\n",
      "\\colorbox{yellow!3}{громких}\n",
      "\\colorbox{yellow!3}{имен}\n",
      "\\colorbox{yellow!5}{актеров}\n",
      "\\colorbox{yellow!2}{и}\n",
      "\\colorbox{yellow!6}{режиссера,}\n",
      "\\colorbox{yellow!3}{а}\n",
      "\\colorbox{yellow!3}{потому,}\n",
      "\\colorbox{yellow!3}{что}\n",
      "\\colorbox{yellow!3}{прочитала}\n",
      "\\colorbox{yellow!4}{книгу.}\n",
      "\\colorbox{yellow!4}{Произведение}\n",
      "\\colorbox{yellow!3}{Кристофера}\n",
      "\\colorbox{yellow!3}{Приста}\n",
      "\\colorbox{yellow!5}{словно}\n",
      "\\colorbox{yellow!5}{схватило}\n",
      "\\colorbox{yellow!3}{меня}\n",
      "\\colorbox{yellow!3}{за}\n",
      "\\colorbox{yellow!5}{душу}\n",
      "\\colorbox{yellow!2}{и}\n",
      "\\colorbox{yellow!3}{не}\n",
      "\\colorbox{yellow!5}{отпускало}\n",
      "\\colorbox{yellow!2}{до}\n",
      "\\colorbox{yellow!2}{самого}\n",
      "\\colorbox{yellow!4}{конца.}\n",
      "\\colorbox{yellow!3}{А}\n",
      "\\colorbox{yellow!2}{вечером}\n",
      "\\colorbox{yellow!3}{я}\n",
      "\\colorbox{yellow!13}{пересказывала}\n",
      "\\colorbox{yellow!39}{историю}\n",
      "\\colorbox{yellow!7}{двух}\n",
      "\\colorbox{yellow!20}{иллюзионистов}\n",
      "\\colorbox{yellow!3}{своей}\n",
      "\\colorbox{yellow!2}{подруге,}\n",
      "\\colorbox{yellow!1}{которая}\n",
      "\\colorbox{yellow!3}{понимала}\n",
      "\\colorbox{yellow!2}{меня}\n",
      "\\colorbox{yellow!2}{с}\n",
      "\\colorbox{yellow!2}{трудом,}\n",
      "\\colorbox{yellow!2}{ведь}\n",
      "\\colorbox{yellow!2}{сам}\n",
      "\\colorbox{yellow!6}{сюжет}\n",
      "\\colorbox{yellow!8}{настолько}\n",
      "\\colorbox{yellow!11}{лихо}\n",
      "\\colorbox{yellow!26}{закручен,}\n",
      "\\colorbox{yellow!13}{а}\n",
      "\\colorbox{yellow!10}{конец}\n",
      "\\colorbox{yellow!12}{просто}\n",
      "\\colorbox{yellow!16}{шедеврален!}\n",
      "\\colorbox{yellow!23}{И}\n",
      "\\colorbox{yellow!9}{на}\n",
      "\\colorbox{yellow!9}{этой}\n",
      "\\colorbox{yellow!55}{позитивной}\n",
      "\\colorbox{yellow!56}{ноте}\n",
      "\\colorbox{yellow!38}{я}\n",
      "\\colorbox{yellow!32}{взялась}\n",
      "\\colorbox{yellow!19}{за}\n",
      "\\colorbox{yellow!16}{фильм.}\n",
      "\\colorbox{yellow!11}{Скажу}\n",
      "\\colorbox{yellow!20}{честно—}\n",
      "\\colorbox{yellow!49}{разочаровал.}\n",
      "\\colorbox{yellow!54}{Скучнее}\n",
      "\\colorbox{yellow!65}{я}\n",
      "\\colorbox{yellow!30}{ничего}\n",
      "\\colorbox{yellow!13}{не}\n",
      "\\colorbox{yellow!47}{видела.}\n",
      "\\colorbox{yellow!9}{После}\n",
      "\\colorbox{yellow!6}{нескольких}\n",
      "\\colorbox{yellow!7}{первых}\n",
      "\\colorbox{yellow!5}{минут}\n",
      "\\colorbox{yellow!10}{я}\n",
      "\\colorbox{yellow!4}{начала}\n",
      "\\colorbox{yellow!3}{«пропадать»}\n",
      "\\colorbox{yellow!4}{в}\n",
      "\\colorbox{yellow!16}{сюжете.}\n",
      "\\colorbox{yellow!25}{Он}\n",
      "\\colorbox{yellow!41}{оказался}\n",
      "\\colorbox{yellow!53}{уж}\n",
      "\\colorbox{yellow!100}{больно}\n",
      "\\colorbox{yellow!41}{запутанным,}\n",
      "\\colorbox{yellow!27}{да}\n",
      "\\colorbox{yellow!13}{так,}\n",
      "\\colorbox{yellow!4}{что,}\n",
      "\\colorbox{yellow!18}{кажется,}\n",
      "\\colorbox{yellow!26}{сценарист}\n",
      "\\colorbox{yellow!18}{сам}\n",
      "\\colorbox{yellow!5}{в}\n",
      "\\colorbox{yellow!11}{нем}\n",
      "\\colorbox{yellow!30}{запутался}\n",
      "\\colorbox{yellow!34}{с}\n",
      "\\colorbox{yellow!45}{режиссером}\n",
      "\\colorbox{yellow!8}{на}\n",
      "\\colorbox{yellow!3}{пару.}\n",
      "\\colorbox{yellow!2}{Всё}\n",
      "\\colorbox{yellow!4}{время}\n",
      "\\colorbox{yellow!26}{пыталась}\n",
      "\\colorbox{yellow!14}{связать}\n",
      "\\colorbox{yellow!10}{происходящее}\n",
      "\\colorbox{yellow!4}{на}\n",
      "\\colorbox{yellow!5}{экране}\n",
      "\\colorbox{yellow!7}{с}\n",
      "\\colorbox{yellow!6}{книгой,}\n",
      "\\colorbox{yellow!13}{но,}\n",
      "\\colorbox{yellow!16}{как}\n",
      "\\colorbox{yellow!7}{ни}\n",
      "\\colorbox{yellow!34}{старалась,}\n",
      "\\colorbox{yellow!17}{ничего}\n",
      "\\colorbox{yellow!78}{общего}\n",
      "\\colorbox{yellow!25}{не}\n",
      "\\colorbox{yellow!16}{нашла.}\n",
      "\\colorbox{yellow!10}{Вкуснейшая}\n",
      "\\colorbox{yellow!32}{интрига}\n",
      "\\colorbox{yellow!5}{Приста}\n",
      "\\colorbox{yellow!5}{была}\n",
      "\\colorbox{yellow!13}{отвратительно}\n",
      "\\colorbox{yellow!17}{чем-}\n",
      "\\colorbox{yellow!12}{то}\n",
      "\\colorbox{yellow!12}{разбавлена.}\n",
      "\\colorbox{yellow!29}{Блюдо}\n",
      "\\colorbox{yellow!41}{остыло}\n",
      "\\colorbox{yellow!8}{и}\n",
      "\\colorbox{yellow!6}{дорога}\n",
      "\\colorbox{yellow!6}{ему}\n",
      "\\colorbox{yellow!5}{на}\n",
      "\\colorbox{yellow!4}{помойку.}\n",
      "\\colorbox{yellow!4}{Единственное,}\n",
      "\\colorbox{yellow!4}{что}\n",
      "\\colorbox{yellow!5}{хоть}\n",
      "\\colorbox{yellow!10}{немного}\n",
      "\\colorbox{yellow!16}{меня}\n",
      "\\colorbox{yellow!16}{порадовало,}\n",
      "\\colorbox{yellow!12}{так}\n",
      "\\colorbox{yellow!11}{это}\n",
      "\\colorbox{yellow!30}{актерский}\n",
      "\\colorbox{yellow!7}{состав.}\n",
      "\\colorbox{yellow!19}{Игра}\n",
      "\\colorbox{yellow!18}{потрясающая,}\n",
      "\\colorbox{yellow!34}{но}\n",
      "\\colorbox{yellow!45}{со}\n",
      "\\colorbox{yellow!18}{Скарлетт}\n",
      "\\colorbox{yellow!4}{что-}\n",
      "\\colorbox{yellow!4}{то}\n",
      "\\colorbox{yellow!3}{было}\n",
      "\\colorbox{yellow!2}{не}\n",
      "\\colorbox{yellow!3}{так.}\n",
      "\\colorbox{yellow!3}{Возможно,}\n",
      "\\colorbox{yellow!4}{дело}\n",
      "\\colorbox{yellow!2}{в}\n",
      "\\colorbox{yellow!4}{самой}\n",
      "\\colorbox{yellow!4}{Оливии.}\n",
      "\\colorbox{yellow!2}{Кажется,}\n",
      "\\colorbox{yellow!2}{в}\n",
      "\\colorbox{yellow!2}{книге}\n",
      "\\colorbox{yellow!2}{этот}\n",
      "\\colorbox{yellow!3}{персонаж}\n",
      "\\colorbox{yellow!1}{был}\n",
      "\\colorbox{yellow!0}{полнее.}\n",
      "\\colorbox{yellow!1}{В}\n",
      "\\colorbox{yellow!1}{общем,}\n",
      "\\colorbox{yellow!1}{в}\n",
      "\\colorbox{yellow!5}{попытке}\n",
      "\\colorbox{yellow!5}{переделать}\n",
      "\\colorbox{yellow!7}{роман}\n",
      "\\colorbox{yellow!2}{на}\n",
      "\\colorbox{yellow!2}{большой}\n",
      "\\colorbox{yellow!3}{экран,}\n",
      "\\colorbox{yellow!3}{была}\n",
      "\\colorbox{yellow!2}{уничтожена}\n",
      "\\colorbox{yellow!3}{вся}\n",
      "\\colorbox{yellow!7}{острота}\n",
      "\\colorbox{yellow!0}{начинки.}\n",
      "\\colorbox{yellow!0}{Для}\n",
      "\\colorbox{yellow!0}{меня,}\n",
      "\\colorbox{yellow!0}{это—}\n",
      "\\colorbox{yellow!0}{худшая}\n",
      "\\colorbox{yellow!0}{экранизация}\n",
      "\\colorbox{yellow!0}{прочитанной}\n",
      "\\colorbox{yellow!0}{книги.}\n",
      "\\colorbox{yellow!0}{Вот}\n",
      "\\colorbox{yellow!0}{так}\n",
      "\\colorbox{yellow!0}{вот,}\n"
     ]
    }
   ],
   "source": [
    "w = alphas_test[0]\n",
    "w /= alphas_test.max() / 100\n",
    "for word, coef in zip(sent.split(), w):\n",
    "    print \"\\colorbox{yellow!%d}{%s}\" % (int(coef), word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сказать что я ждать этот фильм значит ничто не сказать скорсез один из тот режиссёр фильм который я ждать действительно искренне остров проклятый этакий жгучий коктейль молотов фильм без начало и без конец фильм яркий и сочный тенденция к накручивание сюжет быть уже в отступник а здесь он превзойти себя да и другой в жанр психологический триллер настолько гармонично выглядеть весь деталь и нюанс фильм что кажется что ты что то упустить что ты слабый чем фильм а фильм очень сильный музыкальный сопровождение на высокий уровень в прочее как всегда у скорсез ди каприо жечь весь фильм один коронный взгляд и бровь леонардо окупать билет с лихва сам сюжет не новый но бесспорный в исполнение скорсез тянуть на из антураж вышибать мозг на один минута в середина фильм переставать понимать где грань между реальность и вымысел к конец фильм переставать понимать а быть ли реальность реальность а бред бред за это фильм запросто можно назвать один из хороший работа в кинематограф за последний год из </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n"
     ]
    }
   ],
   "source": [
    "print \" \".join(map(id2word.get, X_test[20][:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Фильм вне категорий, не потому что он так хорошо снят или там шикарная актерская игра. Все это там есть, но не это заставляет многих плакать… И не нарочитая слезодавильность. Заставляет очевидная реальность и простота чувств. Я задумался, а почему же слезы у всех? Никто не сказал, что ему жалко Хатико, никто не сказал, что так несправедлива жизнь. Нет в этой истории и нелепых случайностей, что заставляют так сопереживать. \n",
      "\n",
      "Мы плачем потому что понимаем, что мы сами никогда не сможем понять и испытать то, что чувствует Хати. И также полюбить…\n"
     ]
    }
   ],
   "source": [
    "print review_test.text.values[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "фильм вне категория не потому что он так хорошо снятой или там шикарный актёрский игра весь это там есть но не это заставлять многий плакать и не нарочитый заставлять очевидный реальность и простота чувство я задуматься а почему же слеза у весь никто не сказать что он жалко хатико никто не сказать что так несправедливый жизнь нет в этот история и нелепый случайность что заставлять так сопереживать мы плач потому что понимать что мы сам никогда не смочь понять и испытать то что чувствовать хатить и также полюбить </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n"
     ]
    }
   ],
   "source": [
    "print \" \".join(map(id2word.get, X_test[13][:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фильм вне категорий, не потому что он так хорошо снят или там шикарная актерская игра. Все это там есть, но не это заставляет многих плакать… И не нарочитая Заставляет очевидная реальность и простота чувств. Я задумался, а почему же слезы у всех? Никто не сказал, что ему жалко Хатико, никто не сказал, что так несправедлива жизнь. Нет в этой истории и нелепых случайностей, что заставляют так сопереживать. \n",
      "\n",
      "Мы плачем потому что понимаем, что мы сами никогда не сможем понять и испытать то, что чувствует Хати. И также полюбить…\n"
     ]
    }
   ],
   "source": [
    "sentence = u\"\"\"Фильм вне категорий, не потому что он так хорошо снят или там шикарная актерская игра. Все это там есть, но не это заставляет многих плакать… И не нарочитая\"\"\" +\\\n",
    "u\"\"\" Заставляет очевидная реальность и простота чувств. Я задумался, а почему же слезы у всех? Никто не сказал, что ему жалко Хатико, никто не сказал, что так несправедлива жизнь. Нет в этой истории и нелепых случайностей, что заставляют так сопереживать. \n",
    "\n",
    "Мы плачем потому что понимаем, что мы сами никогда не сможем понять и испытать то, что чувствует Хати. И также полюбить…\"\"\"\n",
    "print sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph('model_att.meta')\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "    x_batch_test, y_batch_test = X_test[22:23], y_test[22:23]\n",
    "    seq_len_test = np.array([list(x).index(eos_id) + 1 for x in x_batch_test])\n",
    "    y_pred_test, alphas_test = sess.run([y_hat, alphas],\n",
    "                                                 feed_dict={batch_ph: x_batch_test, target_ph: y_batch_test,\n",
    "                                                            seq_len_ph: seq_len_test, keep_prob_ph: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.67509794,  1.55498695, -5.07856321]], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\colorbox{yellow!7}{Фильм}\n",
      "\\colorbox{yellow!4}{вне}\n",
      "\\colorbox{yellow!6}{категорий,}\n",
      "\\colorbox{yellow!4}{не}\n",
      "\\colorbox{yellow!6}{потому}\n",
      "\\colorbox{yellow!4}{что}\n",
      "\\colorbox{yellow!5}{он}\n",
      "\\colorbox{yellow!9}{так}\n",
      "\\colorbox{yellow!11}{хорошо}\n",
      "\\colorbox{yellow!8}{снят}\n",
      "\\colorbox{yellow!3}{или}\n",
      "\\colorbox{yellow!2}{там}\n",
      "\\colorbox{yellow!4}{шикарная}\n",
      "\\colorbox{yellow!12}{актерская}\n",
      "\\colorbox{yellow!4}{игра.}\n",
      "\\colorbox{yellow!3}{Все}\n",
      "\\colorbox{yellow!1}{это}\n",
      "\\colorbox{yellow!1}{там}\n",
      "\\colorbox{yellow!1}{есть,}\n",
      "\\colorbox{yellow!1}{но}\n",
      "\\colorbox{yellow!2}{не}\n",
      "\\colorbox{yellow!2}{это}\n",
      "\\colorbox{yellow!2}{заставляет}\n",
      "\\colorbox{yellow!2}{многих}\n",
      "\\colorbox{yellow!3}{плакать…}\n",
      "\\colorbox{yellow!2}{И}\n",
      "\\colorbox{yellow!3}{не}\n",
      "\\colorbox{yellow!12}{нарочитая}\n",
      "\\colorbox{yellow!11}{Заставляет}\n",
      "\\colorbox{yellow!38}{очевидная}\n",
      "\\colorbox{yellow!37}{реальность}\n",
      "\\colorbox{yellow!9}{и}\n",
      "\\colorbox{yellow!12}{простота}\n",
      "\\colorbox{yellow!24}{чувств.}\n",
      "\\colorbox{yellow!6}{Я}\n",
      "\\colorbox{yellow!2}{задумался,}\n",
      "\\colorbox{yellow!3}{а}\n",
      "\\colorbox{yellow!4}{почему}\n",
      "\\colorbox{yellow!4}{же}\n",
      "\\colorbox{yellow!20}{слезы}\n",
      "\\colorbox{yellow!7}{у}\n",
      "\\colorbox{yellow!9}{всех?}\n",
      "\\colorbox{yellow!4}{Никто}\n",
      "\\colorbox{yellow!5}{не}\n",
      "\\colorbox{yellow!12}{сказал,}\n",
      "\\colorbox{yellow!6}{что}\n",
      "\\colorbox{yellow!7}{ему}\n",
      "\\colorbox{yellow!11}{жалко}\n",
      "\\colorbox{yellow!7}{Хатико,}\n",
      "\\colorbox{yellow!1}{никто}\n",
      "\\colorbox{yellow!2}{не}\n",
      "\\colorbox{yellow!3}{сказал,}\n",
      "\\colorbox{yellow!2}{что}\n",
      "\\colorbox{yellow!2}{так}\n",
      "\\colorbox{yellow!3}{несправедлива}\n",
      "\\colorbox{yellow!4}{жизнь.}\n",
      "\\colorbox{yellow!1}{Нет}\n",
      "\\colorbox{yellow!0}{в}\n",
      "\\colorbox{yellow!1}{этой}\n",
      "\\colorbox{yellow!3}{истории}\n",
      "\\colorbox{yellow!1}{и}\n",
      "\\colorbox{yellow!12}{нелепых}\n",
      "\\colorbox{yellow!32}{случайностей,}\n",
      "\\colorbox{yellow!8}{что}\n",
      "\\colorbox{yellow!5}{заставляют}\n",
      "\\colorbox{yellow!6}{так}\n",
      "\\colorbox{yellow!10}{сопереживать.}\n",
      "\\colorbox{yellow!10}{Мы}\n",
      "\\colorbox{yellow!11}{плачем}\n",
      "\\colorbox{yellow!4}{потому}\n",
      "\\colorbox{yellow!3}{что}\n",
      "\\colorbox{yellow!7}{понимаем,}\n",
      "\\colorbox{yellow!3}{что}\n",
      "\\colorbox{yellow!3}{мы}\n",
      "\\colorbox{yellow!4}{сами}\n",
      "\\colorbox{yellow!2}{никогда}\n",
      "\\colorbox{yellow!3}{не}\n",
      "\\colorbox{yellow!2}{сможем}\n",
      "\\colorbox{yellow!3}{понять}\n",
      "\\colorbox{yellow!2}{и}\n",
      "\\colorbox{yellow!0}{испытать}\n",
      "\\colorbox{yellow!1}{то,}\n",
      "\\colorbox{yellow!1}{что}\n",
      "\\colorbox{yellow!2}{чувствует}\n",
      "\\colorbox{yellow!1}{Хати.}\n",
      "\\colorbox{yellow!0}{И}\n",
      "\\colorbox{yellow!0}{также}\n",
      "\\colorbox{yellow!0}{полюбить…}\n"
     ]
    }
   ],
   "source": [
    "for word, coef in zip(sentence.split()[:150], alphas_test[0,:150] * 1000 / 1.7):\n",
    "    print \"\\colorbox{yellow!%d}{%s}\" % (int(coef), word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

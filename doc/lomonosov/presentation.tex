\documentclass{beamer}
\usepackage[backend=bibtex]{biblatex}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath,mathrsfs,mathtext}
\usepackage{graphicx, epsfig}
\usepackage{color}
\usepackage{xcolor}
\usetheme{Warsaw}%{Singapore}%{Warsaw}%{Warsaw}%{Darmstadt}
\usecolortheme{sidebartab}
\definecolor{beamer@blendedblue}{RGB}{15,120,80}

\usepackage{multirow}

%----------------------------------------------------------------------------------------------------------
\title[\hbox to 56mm{\hfill\insertframenumber\,/\,\inserttotalframenumber}]
{Рекуррентные нейронные сети с механизмом внимания для анализа тональности русских текстов}
\author[И.\,С. Иванов]{\large \\Иванов Илья Сергеевич$^{1}$
{\large \\Ботвиновский Евгений Александрович$^{2}$}}
\institute{
$^{1}$студент, Московский Физико-Технический Институт\\
$^{2}$к.ф.-м.н., DeepHackLab\\
}
\date{2017}
%----------------------------------------------------------------------------------------------------------
\begin{document}
\nocite{*}
%----------------------------------------------------------------------------------------------------------
\begin{frame}
%\thispagestyle{empty}
\titlepage
\end{frame}
%-----------------------------------------------------------------------------------------------------
\begin{frame}{Цель исследования}
Исследовать новые методы анализа тональности коротких текстов на русском языке с применением рекуррентных нейронных сетей и механизма внимания.
\begin{block}{Проблемы}
	Сложная морфология русского языка.\\
	Особенности лексикона пользователей соц. сети.\\
	Малый объём данных для обучения.\\
\end{block}

\begin{block}{Предположения}
	Зависимость класса от порядка слов в тексте.\\
	Разная значимость слов в тексте при классификации.
\end{block}

\end{frame}
%-----------------------------------------------------------------------------------------------------
\begin{frame}{Литература}
	\begin{enumerate}
		\item Arkhipenko K., Kozlov I., Trofimovich J., Skorniakov K., Gomzin A., Turdakov D.. Comparison of Neural Network Architectures for Sentiment Analysis of Russian Tweets. Computational Linguistics and Intellectual Technologies. Dialog, 2016.	
		\item Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He, Alexander J. Smola, Eduard H. Hovy. Hierarchical Attention Networks for Document Classification. HLT-NAACL, 2016.
		\item Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural Machine Translation by Jointly Learning to Align and Translate. ICLR, 2014.
	\end{enumerate}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Постановка задачи классификации}
	\begin{block}{}
        Дано множество коротких сообщений $\mathfrak{D} = \{\mathbf{d}_j\}_{j=1}^{K}$ с упоминанием некоторых компаний.
	\end{block}    
    
    \begin{block}{}
        Необходимо классифицировать сообщения из $\mathfrak{D}$ на три класса:
        	\begin{enumerate}
			\item положительной тональности (положительные);
			\item отрицательной тональности (отрицательные);
			\item не имеющие тональности (нейтральные).
			\end{enumerate}
	\end{block}
	
	\begin{block}{Функционалы качества}
		Макро-усредненная F-мера
относительно классов положительных и
отрицательных сообщений.
	\end{block}
	В качестве классификатора предлагается использовать двунаправленную рекуррентную нейронную сеть с механизмом внимания.
\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Векторное представление слов}
	\begin{itemize}
	\item Сообщение $\mathbf{d}\in\mathfrak{D}$ является последовательностью слов $\mathbf{d}=\mathbf{w}_1..\mathbf{w}_T$ из словаря $\mathfrak{W}$.\\
	\item Слово $\mathbf{w}\in\mathfrak{W}$ представляется вектором в $D$-мерном пространстве.\\
	\item Векторное представление для всех слов из словаря получается при помощи алгоритма Word2Vec, применённом на большом наборе неразмеченных данных.
	\end{itemize}
\begin{figure}[!h]
  \includegraphics[width=1.0\textwidth]{images/word2vec.png}
\end{figure}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Рекуррентная нейронная сеть}
	\begin{itemize}
	\item В качестве классификатора используется двунаправленная рекуррентная нейронная сеть типа GRU (Gated Recurrent Unit) с механизмом внимания.\\
	\item Функцией ошибки является перекрёстная энтропия для трёх классов.\\
	$$ J(W)=-\sum_{i=1}^{n}\sum_{k=1}^{3}y_{i}^{(k)}\log{\hat{y_{i}}^{(k)}},
	$$$$
	\hat{y_{i}}^{(k)} = \frac{\exp{s_{i}^{(k)}}}{\sum_{j=1}^{3}\exp{s_{i}^{(j)}}}
	$$
	\end{itemize}

\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Двунаправленный GRU}
	\begin{block}{Уравнения GRU}
	\begin{align}
	z_{t}&=\sigma_{g}(W_{z}x_{t}+U_{z}h_{t-1})\\
	r_{t}&=\sigma_{g}(W_{r}x_{t}+U_{r}h_{t-1})\\
	\tilde{h}_{t}&=\tanh(Wx_{t}+U(r_{t}\circ h_{t-1}))\\
	h_{t}&=(1-z_{t})\circ \tilde{h}_{t}+z_{t}\circ h_{t-1}
	\end{align}	
% LSTM
%		f_{t}&=\sigma_{g}(W_{f}x_{t}+U_{f}h_{t-1}+b_{f})\\
%	i_{t}&=\sigma_{g}(W_{i}x_{t}+U_{i}h_{t-1}+b_{i})\\
%	o_{t}&=\sigma_{g}(W_{o}x_{t}+U_{o}h_{t-1}+b_{o})\\
%	c_{t}&=f_{t}\circ c_{t-1}+i_{t}\circ \sigma_{c}(W_{c}x_{t}%+U_{c}h_{t-1}+b_{c})\\
%	h_{t}&=o_{t}\circ \sigma_{h}(c_{t})

	\end{block}
\begin{figure}[!h]
  \includegraphics[width=0.3\textwidth]{images/birnn2_bin.png}
\end{figure}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Механизм внимания}
	\begin{block}{Уравнения механизма внимания}
	\begin{align}
	\upsilon_{t}&=\tanh{(W_{\omega}\left[\overrightarrow{h_{t}},\overleftarrow{h_{t}}\right]+b_{\omega})}\\
	\alpha_{t}&=\frac{\exp{(\upsilon_{t}^{T}u_{\omega})}}{\sum_{j=1}^{T}\exp{(\upsilon_{j}^{T}u_{\omega})}}\\
	\upsilon&=\sum_{t=1}^{T}\alpha_{t}\left[\overrightarrow{h_{t}},\overleftarrow{h_{t}}\right]
	\end{align}	
	\end{block}
\begin{figure}[!h]
  \includegraphics[width=0.25\textwidth]{images/att_edited.png}
\end{figure}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Набор данных}
	В качестве коллекции документов $\mathfrak{D}$ используется набор сообщений пользователей соц. сети Twitter с упоминанием некоторых банков и телекоммуникационных компаний, собираемые с 2013-го года. Особенностями данной коллекции являются:
	\begin{itemize}
	\item Размер сообщения - не более 140 символов
	\item Лексикон:
		\begin{itemize}
			 \item сленг
			 \item сокращения
			 \item эмотиконы		
		\end{itemize}
	\item Спец. символы:
		\begin{itemize}
			 \item \# (хэштег)
			 \item @ (ссылка на пользователя)
		\end{itemize}
	\item Ссылки на внешние ресурсы
	\end{itemize}
\end{frame}
%-----------------------------------------------------------------------------------------------
\begin{frame}{Цели эксперимента}
	\begin{enumerate}
		\item Реализовать архитектуру двунаправленной рекуррентной сети с механизмом внимания (Python + TensorFlow)
		\item Обучить модель на предложенных выборках
		\item Сравнить результаты с предложенными ранее алгоритмами.
	\end{enumerate}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Вычислительный эксперимент}
В ходе эксперимента сравниваются результаты предложенного алгоритма классификации с такими алгоритмами как двунаправленная рекуррентная нейронная сеть (без механизма внимания), метод опорных векторов и другие. \\
\begin{block}{План эксперимента}
	\begin{enumerate}
		\item Предобработать наборы текстов
		\item Реализовать двунаправленный GRU с механизмом внимания
		\item Обучить модель на обучающей выборке
		\item Протестировать модель на отложенной выборке
		\item Сравнить результаты с другими алгоритмами
	\end{enumerate}
\end{block}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Предобработка данных}

\begin{enumerate}
	\item Токенизация (NLTK)
	\item Лемматизация (PyMorphy2)
	\item Векторизация слов (Word2Vec, обученный на русскоязычном корпусе из социальных медиа)
	\item Дополнение последовательностей нулями до максимальной длины (zero-padding)
	
\end{enumerate}
\end{frame}

%----------------------------------------------------------------------------------------------------------
\begin{frame}{Предобработка данных}

\begin{figure}[!h]
\caption{Распределение кол-ва слов в сообщении}
  \includegraphics[width=0.5\textwidth]{images/mess_len_bank.png}
    \includegraphics[width=0.5\textwidth]{images/mess_len_tkk2.png}
\end{figure}

\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Визуализация механизма внимания}

%\colorbox{yellow!0}{Вчера}
%\colorbox{yellow!0}{был}
%\colorbox{yellow!0}{в}
%\colorbox{yellow!0}{центральном}
%\colorbox{yellow!0}{офисе}
%\colorbox{yellow!3}{сбербанка}
%\colorbox{yellow!8}{в}
%\colorbox{yellow!14}{Волгограде.}
%\colorbox{yellow!42}{Уж}
%\colorbox{yellow!47}{насколько}
%\colorbox{yellow!89}{я}
%\colorbox{yellow!100}{его}
%\colorbox{yellow!67}{не}
%\colorbox{yellow!53}{люблю,}
%\colorbox{yellow!29}{но}
%\colorbox{yellow!26}{настолько}
%\colorbox{yellow!14}{был}
%\colorbox{yellow!13}{вчера}
%\colorbox{yellow!6}{удивлен}
%\colorbox{yellow!4}{что}
%\colorbox{yellow!12}{грех}
%\colorbox{yellow!4}{не}
%\colorbox{yellow!2}{похвалить.}
1.
\colorbox{yellow!70}{Почему-то}
\colorbox{yellow!100}{не}
\colorbox{yellow!57}{приходят}
\colorbox{yellow!17}{смс-сообщения}
\colorbox{yellow!5}{для}
\colorbox{yellow!7}{подтверждения}
\colorbox{yellow!0}{входа}
\linebreak
\linebreak
\linebreak
2.
\colorbox{yellow!3}{IPhone-овское}
\colorbox{yellow!2}{приложение}
\colorbox{yellow!2}{от}
\colorbox{yellow!30}{Сбербанка}
\colorbox{yellow!89}{самое}
\colorbox{yellow!100}{удобное}
\colorbox{yellow!84}{в}
\colorbox{yellow!82}{России}

%\colorbox{yellow!100}{Отказ}
%\colorbox{yellow!80}{Сбербанка}
%\colorbox{yellow!56}{от}
%\colorbox{yellow!44}{Про100}
%\colorbox{yellow!24}{может}
%\colorbox{yellow!24}{создать}
%\colorbox{yellow!27}{проблемы}
%\colorbox{yellow!7}{для}
%\colorbox{yellow!13}{жителей}
%\colorbox{yellow!43}{Крыма}

%\colorbox{yellow!3}{@RSHBmedia}
%\colorbox{yellow!87}{почему}
%\colorbox{yellow!100}{такой}
%\colorbox{yellow!69}{неудобный}
%\colorbox{yellow!71}{и}
%\colorbox{yellow!69}{не}
%\colorbox{yellow!68}{информативный}
%\colorbox{yellow!3}{интернет-}
%\colorbox{yellow!3}{банк?}
%\colorbox{yellow!8}{Учитесь}
%\colorbox{yellow!16}{у}
%\colorbox{yellow!3}{@sberbank}
%\colorbox{yellow!17}{и}
%\colorbox{yellow!12}{его}
%\colorbox{yellow!19}{Сбербанк-}
%\colorbox{yellow!1}{онлайн.}

%\colorbox{yellow!14}{Заведение}
%\colorbox{yellow!41}{вполне}
%\colorbox{yellow!62}{приличное,}
%\colorbox{yellow!78}{кухня}
%\colorbox{yellow!99}{хорошая,}
%\colorbox{yellow!27}{но}
%\colorbox{yellow!25}{маловато}
%\colorbox{yellow!11}{выбора,}
%\colorbox{yellow!8}{зато}
%\colorbox{yellow!2}{с}
%\colorbox{yellow!2}{напитками}
%\colorbox{yellow!2}{никакой}
%\colorbox{yellow!2}{проблемы}
%\colorbox{yellow!3}{выбора}
%\colorbox{yellow!2}{нет!!}
%\colorbox{yellow!2}{много}
%\colorbox{yellow!2}{сортов}
%\colorbox{yellow!2}{пива}
%\colorbox{yellow!3}{и}
%\colorbox{yellow!2}{других}
%\colorbox{yellow!1}{более}
%\colorbox{yellow!2}{крепких}
%\colorbox{yellow!1}{напитков.}
%\colorbox{yellow!1}{из}
%\colorbox{yellow!3}{минусов}
%\colorbox{yellow!3}{можно}
%\colorbox{yellow!4}{сказать}
%\colorbox{yellow!4}{только}
%\colorbox{yellow!10}{черезмерная}
%\colorbox{yellow!8}{громкость}
%\colorbox{yellow!12}{живой}
%\colorbox{yellow!8}{музыки}
%\colorbox{yellow!4}{по}
%\colorbox{yellow!5}{выходным.}
%\colorbox{yellow!6}{соседа}
%\colorbox{yellow!11}{не}
%\colorbox{yellow!11}{слышно....}

\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Сравнение качества полученных моделей}

\begin{table}[]
\centering
\caption{F1-мера различных моделей на кросс-валидации (CV) и на тестовой выборке}
\label{tab:res}
{\small
\begin{tabular}{l|l|l|l|l|}
\cline{2-5}
                                                                                                              & \multicolumn{2}{c|}{Banks}   & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}Telecommunication\\ companies\end{tabular}} \\ \cline{2-5}                                                                                                               
                                                                                                              & \begin{tabular}[c]{@{}l@{}}5-fold CV\\(mean, std)\end{tabular}  & test & \begin{tabular}[c]{@{}l@{}}5-fold CV\\(mean, std)\end{tabular}                                & test                                \\ \hline
\multicolumn{1}{|l|}{Bi-GRU}                                                                                  & 0.74, 0.02            & 0.48 & 0.62, 0.01                                                     & 0.52                                \\ \hline
\multicolumn{1}{|l|}{Bi-GRU + Attention}                                                                      & 0.74, 0.02            & 0.51 & 0.60, 0.02                                           & 0.49                                \\ \hline
\multicolumn{1}{|l|}{\begin{tabular}[c]{@{}l@{}}2-layer GRU,\\ reversed sequences\\ (Arhipenko)\end{tabular}} & 0.62, -               & 0.55 & 0.66, -                                              & 0.56                                \\ \hline
\multicolumn{1}{|l|}{Bi-GRU (Arhipenko)}                                                                      & 0.62, -               & -    & 0.65, -                                              & -                                   \\ \hline
\multicolumn{1}{|l|}{LSTM (Arhipenko)}                                                                        & 0.60, -               & -    & 0.64, -                                              & -                                   \\ \hline
\multicolumn{1}{|l|}{CNN (Arhipenko)}                                                                         & -                     & 0.48 & -                                                    & 0.47                                \\ \hline
\multicolumn{1}{|l|}{SVM baseline}                                                                            & -                     & 0.46 & -                                                    & 0.46                                \\ \hline
\multicolumn{1}{|l|}{Majority baseline}                                                                       & -                     & 0.31 & -                                                    & 0.19                                \\ \hline
\end{tabular}
}
\end{table}

\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Сравнение качества полученных моделей}

\begin{table}[]

\centering
\caption{Результаты эксперимента со смешиванием обучающей и тестовой выборок}
\label{tab:mix}
\setlength\tabcolsep{1.5pt}
{\small
\begin{tabular}{l|c|l|l|c|l|l|}
\cline{2-7}
                                         & \multicolumn{3}{c|}{Banks}                                                                                     & \multicolumn{3}{c|}{\begin{tabular}[c]{@{}c@{}}Telecommunication\\ companies\end{tabular}}                     \\ \cline{2-7} 
                                         & \multicolumn{2}{c|}{cross-validation}                             & \multicolumn{1}{c|}{\multirow{2}{*}{test}} & \multicolumn{2}{c|}{cross-validation}                             & \multicolumn{1}{c|}{\multirow{2}{*}{test}} \\ \cline{2-3} \cline{5-6}
                                         & train                           & \multicolumn{1}{c|}{train+test} & \multicolumn{1}{c|}{}                      & train                           & \multicolumn{1}{c|}{train+test} & \multicolumn{1}{c|}{}                      \\ \hline
\multicolumn{1}{|l|}{Bi-GRU}             & \multicolumn{1}{l|}{0.74, 0.02} & 0.71, 0.02                      & 0.48                                       & \multicolumn{1}{l|}{0.62, 0.01} & 0.62, 0.01                      & 0.52                                       \\ \hline
\multicolumn{1}{|l|}{Bi-GRU+Attention} & \multicolumn{1}{l|}{0.74, 0.02} & 0.72, 0.01                      & 0.51                                       & \multicolumn{1}{l|}{0.60, 0.02} & 0.62, 0.01                      & 0.49                                       \\ \hline
\end{tabular}
}
\end{table}

\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Заключение}

	\begin{itemize}
		\item Реализован алгоритм двунаправленной рекуррентной нейронной сети с механизмом внимания для классификации тональности коротких русскоязычных текстов. Код отлажен и выложен в открытый доступ
		\item Модель обучена на вышеупомянутых выборках
		\item Проведено сравнение результатов с предложенными ранее алгоритмами
		\item Подготовлен отчет по результатам работы
	\end{itemize}

	\begin{block}{Дальнейшее исследование}
		Исследование применимости данной модели в качестве модуля для нейронной сети, генерирующей сообщения с заданной тональностью.
	\end{block}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\end{document} 
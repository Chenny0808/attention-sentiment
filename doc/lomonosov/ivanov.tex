%
%   Образец / Шаблон оформления тезиса
%
%
%   Если в тезисе каких-то разделов (картинок, списка литературы) нет, то соотвествующие команды надо закомментировать.
%   Файл для компиляции --- этот (example.tex, переименовый в фамилию автора, например, ivanov.tex).
%
%   ========================================================================================
%


%
%   Если в вашем документе нет картинок и вы хотите компилировать документ при помощи latex->dvips->ps2pdf, то уберите опцию usePics, заменив следующую строчку на
\documentclass{lomonosov}
%\documentclass[usePics]{lomonosov}
\begin{thesis}  % Сам тезис должен быть полностью помещен внутри окружения thesis

% Один автор
%\Title{Рекуррентные нейронные сети с механизмом внимания для анализа тональности русских текстов}{{Иванов\,И.\,С.}}
% Несколько авторов
\Title{Рекуррентные нейронные сети с механизмом внимания для анализа тональности русских текстов}{{Иванов\,И.\,С.}{Ботвиновский\,Е.\,А.}}

%
%   Команда авторства. Выберете ту, что отвечает вашему тезису, и, если надо, раскомментируйте ее; остальные --- удалите или закомментируйте.
%

% Один автор
%\Author{Иванов~Илья~Сергеевич}{Студент}{Факультет ФИВТ МФТИ (ГУ)}{Долгопрудный}{Россия}{ilya.ivanov.se@gmail.com}

% Несколько авторв из одной организации
%\Author{Ильин Александр Владимирович, Шевцова Ирина Геннадьевна}{Математик, ассистент}{Факультет ВМК МГУ имени М.\,В.\,Ломоносова}{Москва}{Россия}{smu@cs.msu.ru, lomonosov@cs.msu.ru}

% Несколько авторов из разных организаций
\AuthorM{{Иванов~Илья~Сергеевич}{Ботвиновский~Евгений~Александрович}}{
   {студент, факультет ФИВТ МФТИ (ГУ), Долгопрудный, Россия}{к.ф.-м.н., \ENGLISH{DeepHackLab}, Долгопрудный, Россия}}{ilya.ivanov.se@gmail.com, botvinovski@gmail.com}

Анализ сообщений в социальных медиа ресурсах представляет огромный практический интерес со стороны бизнеса, поскольку мнение пользователей влияет на покупательскую способность. В частности, одной из актуальных и практически важных задач для бизнеса является анализ тональности~[1].

Для тестирования алгоритмов определения тональности существуют специальные конкурсы в рамках ежегодных соревнований (например, \ENGLISH{SemEval}, конференция <<Диалог>>), а также открытые наборы данных~[1,2,3].

В данной работе рассматривается задача классификации русских текстов по тональности. В качестве классификаторов используются такие модели как двунаправленная рекуррентная нейронная сеть и двунаправленная рекуррентная нейронная сеть с механизмом внимания~[3,4]. Целью является сравнение данных моделей. Рассматриваемые в работе классификаторы экспериментально проверялись на наборе русских сообщений из \ENGLISH{Twitter}, представленных на соревновании \ENGLISH{Dialogue Evaluate 2016}.

Предварительно текст обрабатывается при помощи \ENGLISH{Python} библиотеки \ENGLISH{\texttt{pymorphy2}}, позволяющей проводить лемматизацию слов. Для получения векторных представлений слов используется алгоритм \ENGLISH{Word2Vec}. Далее последовательность векторов, кодирующая одно сообщение, подается на вход рекуррентной сети.

В Таблице \ref{tab:res} представлены результаты 5-фолд кросс-валидации различных моделей на обучающей выборке и результаты на тестовой выборке. Используемая метрика - макро-усреднённая \ENGLISH{F1}-мера по классам положительной и отрицательной тональностей. Помимо наших экспериментов в таблице представлены результаты победителя~[5]  и бейзлайны соревновательной дорожки по анализу тональности \ENGLISH{Dialogue Evaluate 2016}. Здесь стоит отметить, что решения участников соревнования содержали различные дополнительные методы обработки данных, помимо лемматизации, которые мы не использовали.

%\setlength{\textfloatsep}{5pt}  % space between table and text

\begin{table}[]
\centering
\caption{\ENGLISH{F1}-мера различных моделей на кросс-валидации (\ENGLISH{CV}) и на тестовой выборке}
\label{tab:res}
\setlength{\tabcolsep}{.3em}

\begin{tabular}{l|l|l|l|l|}
\cline{2-5}
                                                                                                              & \multicolumn{2}{c|}{Банки}   & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}Телекоммуникационные\\компании\end{tabular}} \\ \cline{2-5}
& \begin{tabular}[c]{@{}l@{}}\ENGLISH{CV(mean, std)}\end{tabular}  & \ENGLISH{test} & \begin{tabular}[c]{@{}l@{}}\ENGLISH{CV(mean, std)}\end{tabular}                                & \ENGLISH{test} \\ \hline
\multicolumn{1}{|l|}{\ENGLISH{Bi-GRU}}                                                                                  & 0.74, 0.02            & 0.48 & 0.62, 0.01                                                     & 0.52                                \\ \hline
\multicolumn{1}{|l|}{\ENGLISH{Bi-GRU+Attention}}                                                                      & 0.74, 0.02            & 0.51 & 0.60, 0.02                                           & 0.49                                \\ \hline
\multicolumn{1}{|l|}{\begin{tabular}[c]{@{}l@{}}\ENGLISH{2-layer GRU,\\ reversed sequences\\ (Arhipenko)}\end{tabular}} & 0.62, -               & 0.55 & 0.66, -                                              & 0.56                                \\ \hline
\multicolumn{1}{|l|}{\ENGLISH{CNN (Arhipenko)}}                                                                         & -                     & 0.48 & -                                                    & 0.47                                \\ \hline
\multicolumn{1}{|l|}{\ENGLISH{SVM baseline}}                                                                            & -                     & 0.46 & -                                                    & 0.46                                \\ \hline

\end{tabular}
\end{table}

Видно, что лишь на одном из двух доменов алгоритм с исследуемым механизмом внимания превзошёл аналогичный алгоритм без механизма внимания. Весь код решения и значения гиперпараметров доступны по ссылке \url{www.github.com/ilivans/tf-rnn-attention}.

Также из таблицы видно, что значения \ENGLISH{F1}-меры на обучающей и тестовой выборке существенно отличаются. Мы провели ряд экспериментов, для того чтобы найти гиперпараметры, при которых бы отсутствовало переобучение алгоритмов. Однако эта разница наблюдалась во всех наших экспериментах, как при уменьшении размера сети, так и с увеличением параметра \ENGLISH{dropout}~[6]. Чтобы исследовать причины этого расхождения, мы провели эксперимент со смешиванием обучающей и тестовой выборок и последующей кросс-валидацией моделей на смешанной выборке. Результаты данного эксперимента приведены в Таблице \ref{tab:mix}. Судя по тому, что кросс-валидация на смешанной выборке показала результаты очень близкие к кросс-валидации на обучающей выборке, можно предположить, что между обучающей и тестовой выборками есть существенные различия. Однако для тщательной проверки этой гипотезы требуется провести детальный сравнительный анализ данных, что авторы планируют проделать в будущем.

\begin{table}[]
\centering
\caption{Результаты эксперимента со смешиванием обучающей и тестовой выборок}
\label{tab:mix}
\setlength{\tabcolsep}{.3em}

\begin{tabular}{l|c|c|c|c|}
\cline{2-5}
                                       & \multicolumn{2}{c|}{Банки}            & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}Телекоммуникационные\\ компании\end{tabular}} \\ \cline{2-5} 
                                       & \multicolumn{2}{c|}{CV(mean,std)} & \multicolumn{2}{c|}{CV(mean,std)}                                                        \\ \cline{2-5} 
                                       & train              & train+test       & train                                         & train+test                                   \\ \hline
\multicolumn{1}{|l|}{Bi-GRU}           & 0.74, 0.02         & 0.71, 0.02       & 0.62, 0.01                                    & 0.62, 0.01                                   \\ \hline
\multicolumn{1}{|l|}{Bi-GRU+Attention} & 0.74, 0.02         & 0.72, 0.01       & 0.60, 0.02                                    & 0.62, 0.01                                   \\ \hline
\end{tabular}

\end{table}

Таким образом, исследована применимость модели на основе двунаправленной рекуррентной нейронной сети с механизмом внимания в задаче классификации тональности русскоязычных текстов. Проведено сравнение данной модели с её ранее изученными аналогами. В будущем планируется провести эксперименты на других, более сбалансированных и крупных, наборах данных.

%
%   Список литературы, если он есть
%
\begin{references}

\Source Рубцова\,Ю. 
	Построение корпуса текстов для настройки тонового классификатора
	// Программные продукты и системы, 
	2015, C.\,72--78.

\Source \ENGLISH{Maas\,A., Daly\,R., Pham\,P., Huang\,D., Ng\,A., Potts\,C.
	Learning Word Vectors for Sentiment Analysis 
	// Proceedings of the 49th Annual Meeting of 
	the Association for Computational Linguistics: Human Language Technologies, 
	Stroudsburg, USA, 2011, Vol.1, P.\,142--150.}

\Source \ENGLISH{Yang\,Z., Yang\,D., Dyer\,C., He\,X., Smola\,A., Hovy\,E. 
	Hierarchical attention networks for document classification 
	// Proceedings of the 15th Conference of the North American Chapter of 
	the Association for Computational Linguistics: Human Language Technologies, 
	San Diego, USA, 2016, P.\,1480--1489.}

\Source \ENGLISH{Bahdanau\,D., Cho\,K., Bengio\,Y. 
	Neural Machine Translation by Jointly Learning to Align and Translate
	// Computing Research Repository, 
	2014, Vol. abs/1409.0473}

\Source \ENGLISH{Arkhipenko\,K., Kozlov\,I., Trofimovich\,J., Skorniakov\,K., Gomzin\,A., Turdakov\,D. 
	Comparison of Neural Network Architectures for Sentiment Analysis of Russian Tweets 
	// Proceedings of the International Conference <<Dialogue 2016>>, 
	2016, Vol.15, P.\,50--58.}

\Source \ENGLISH{Srivastava\,N., Hinton\,G., Krizhevsky\,A., Sutskever\,I., Salakhutdinov\,R. 
	Dropout: A Simple Way to Prevent Neural Networks from Overfitting
	// The Journal of Machine Learning Research, 
	2014, Vol.\,15, \No\,1, P.\,1929--1958.}

\end{references}

\end{thesis} % Сам тезис должен быть полностью помещен внутри окружения thesis

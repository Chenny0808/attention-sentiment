\chapter{Вычислительный эксперимент}

\section{Твиты}
В Таблице \ref{tab:res_twitter} представлены результаты 5-фолд кросс-валидации различных моделей на обучающей подвыборке и результаты на тестовой подвыборке для набора с твитами. Используемая метрика - макро-усреднённая F1-мера по классам положительной и отрицательной тональностей. Помимо наших экспериментов в таблице представлены результаты победителя~\cite{arhipenko}  и бейзлайны соревновательной дорожки по анализу тональности Dialogue Evaluate 2016~\cite{senti-ru-eval}. Здесь стоит отметить, что решения участников соревнования содержали различные дополнительные методы обработки данных, такие как, например, удаление полудубликатов из обучающей выборки.

Видно, что лишь на одном из двух доменов алгоритм с исследуемым механизмом внимания превзошёл аналогичный алгоритм без механизма внимания.

\begin{table}[H]
\centering
\caption{F1-мера различных моделей на кросс-валидации (CV) и на тестовой выборке}
\label{tab:res_twitter}
    \begin{tabular}{l|l|l|l|l|}
    \cline{2-5}
                                                                                                                  & \multicolumn{2}{c|}{Banks}   & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}Telecommunication\\ companies\end{tabular}} \\ \cline{2-5}                                                                                                               
                                                                                                                  & \begin{tabular}[c]{@{}l@{}}5-fold CV\\(mean, std)\end{tabular}  & test & \begin{tabular}[c]{@{}l@{}}5-fold CV\\(mean, std)\end{tabular}                                & test                                \\ \hline
    \multicolumn{1}{|l|}{Bi-GRU}                                                                                  & 0.74, 0.02            & 0.48 & 0.62, 0.01                                                     & 0.52                                \\ \hline
    \multicolumn{1}{|l|}{Bi-GRU + Attention}                                                                      & 0.74, 0.02            & 0.51 & 0.60, 0.02                                           & 0.49                                \\ \hline
    \multicolumn{1}{|l|}{\begin{tabular}[c]{@{}l@{}}2-layer GRU,\\ reversed sequences\\ (Arhipenko)\end{tabular}} & 0.62, -               & 0.55 & \textbf{0.66}, -                                              & \textbf{0.56}                                \\ \hline
    \multicolumn{1}{|l|}{Bi-GRU (Arhipenko)}                                                                      & 0.62, -               & -    & 0.65, -                                              & -                                   \\ \hline
    \multicolumn{1}{|l|}{LSTM (Arhipenko)}                                                                        & 0.60, -               & -    & 0.64, -                                              & -                                   \\ \hline
    \multicolumn{1}{|l|}{CNN (Arhipenko)}                                                                         & -                     & 0.48 & -                                                    & 0.47                                \\ \hline
    \multicolumn{1}{|l|}{SVM baseline}                                                                            & -                     & 0.46 & -                                                    & 0.46                                \\ \hline
    \multicolumn{1}{|l|}{Majority baseline}                                                                       & -                     & 0.31 & -                                                    & 0.19                                \\ \hline
    \end{tabular}
\end{table}

Также из таблицы видно, что значения F1-меры на обучающей и тестовой выборке существенно отличаются. Мы провели ряд экспериментов, для того чтобы найти гиперпараметры, при которых бы удалось уменьшить переобучение алгоритмов. Однако эта разница наблюдалась во всех наших экспериментах, как при уменьшении размера сети, так и с увеличением параметра регуляризации dropout~\cite{srivastava}. Чтобы исследовать причины этого расхождения, мы провели эксперимент со смешиванием обучающей и тестовой выборок и последующей кросс-валидацией моделей на смешанной выборке. Результаты данного эксперимента приведены в Таблице \ref{tab:mix}. Стоит отметить, что размеры обучающей и тестовой выборок сравнимы (5:2). Судя по тому, что кросс-валидация на смешанной выборке показала результаты очень близкие к кросс-валидации на обучающей выборке, можно предположить, что между обучающей и тестовой выборками есть существенные различия. Однако для тщательной проверки этой гипотезы требуется провести детальный сравнительный анализ данных, что авторы планируют проделать в будущем.

\begin{table}[H]
\centering
\caption{Результаты эксперимента со смешиванием обучающей и тестовой выборок, метрика - F1}
\label{tab:mix}
{\setlength{\tabcolsep}{0.25em}
\begin{tabular}{l|c|l|l|c|l|l|}
\cline{2-7}
                                         & \multicolumn{3}{c|}{Banks}                                                                                     & \multicolumn{3}{c|}{\begin{tabular}[c]{@{}c@{}}Telecommunication\\ companies\end{tabular}}                     \\ \cline{2-7} 
                                         & \multicolumn{2}{c|}{cross-validation}                             & \multicolumn{1}{c|}{\multirow{2}{*}{test}} & \multicolumn{2}{c|}{cross-validation}                             & \multicolumn{1}{c|}{\multirow{2}{*}{test}} \\ \cline{2-3} \cline{5-6}
                                         & train                           & \multicolumn{1}{c|}{train+test} & \multicolumn{1}{c|}{}                      & train                           & \multicolumn{1}{c|}{train+test} & \multicolumn{1}{c|}{}                      \\ \hline
\multicolumn{1}{|l|}{Bi-GRU}             & \multicolumn{1}{l|}{0.74, 0.02} & 0.71, 0.02                      & 0.48                                       & \multicolumn{1}{l|}{0.62, 0.01} & 0.62, 0.01                      & 0.52                                       \\ \hline
\multicolumn{1}{|l|}{Bi-GRU+Attention} & \multicolumn{1}{l|}{0.74, 0.02} & 0.72, 0.01                      & 0.51                                       & \multicolumn{1}{l|}{0.60, 0.02} & 0.62, 0.01                      & 0.49                                       \\ \hline
\end{tabular}}
\end{table}

%------------------------------------------------------------------------------
\section{Отзывы на товары и рестораны}
В Таблице \ref{tab:res_reviews} представлены результаты 10-фолд кросс-валидации различных моделей на обучающей подвыборке и результаты на тестовой подвыборке для набора отзывов на товары и рестораны. Используемые метрики - точность (accuracy) и макро-усреднённая F1-мера по классам положительной и отрицательной тональностей.

\begin{table}[H]
	\centering
	\caption{Качество различных моделей на кросс-валидации (CV) и тестовой подвыборке для набора с отзывами}
	\label{tab:res_reviews}
	\begin{tabular}{l|l|l|l|l|}
		\cline{2-5}
		& \multicolumn{4}{c|}{Reviews}                                                                                      \\ \cline{2-5} 
		& \multicolumn{2}{c|}{10-fold CV}                         & \multicolumn{2}{c|}{test}                               \\ \cline{2-5} 
		& \multicolumn{1}{c|}{accuracy} & \multicolumn{1}{c|}{F1} & \multicolumn{1}{c|}{accuracy} & \multicolumn{1}{c|}{F1} \\ \hline
		\multicolumn{1}{|l|}{Bi-GRU}           & 0.906, 0.003                  & 0.863, 0.007            & \textbf{0.901}                         & \textbf{0.861}                   \\ \hline
		\multicolumn{1}{|l|}{Bi-GRU+Attention} & 0.907, 0.004                  & 0.865, 0.007            & 0.900                         & \textbf{0.861}                   \\ \hline
		\multicolumn{1}{|l|}{CNN}              & 0.901, 0.003                  & 0.854, 0.005            & 0.896                         & 0.844                   \\ \hline
		\multicolumn{1}{|l|}{SVM}              & 0.897, 0.004                  & 0.838, 0.006            & 0.895                         & 0.836                   \\ \hline
		\multicolumn{1}{|l|}{Majority baseline}              & -                  & -            & 0.793                         & 0.442                   \\ \hline
	\end{tabular}
\end{table}

Как видно из таблицы, в эксперименте с отзывами предложенный алгоритм также не превзошёл двунаправленную рекуррентную нейронную сеть.

%------------------------------------------------------------------------------
\section{Рецензии на фильмы}
В Таблице \ref{tab:res_kinopoisk} представлены результаты 10-фолд кросс-валидации различных моделей на обучающей подвыборке и результаты на тестовой подвыборке для набора рецензий на фильмы. Используемые метрики - точность (accuracy) и макро-усреднённая F1-мера по всем трём классам.

\begin{table}[H]
	\centering
	\caption{Качество различных моделей на кросс-валидации (CV) и тестовой подвыборке для набора с рецензиями}
	\label{tab:res_kinopoisk}
	\begin{tabular}{l|l|l|l|l|}
        \cline{2-5}
                                                & \multicolumn{4}{c|}{Reviews}                                                                                      \\ \cline{2-5} 
                                                & \multicolumn{2}{c|}{10-fold CV}                         & \multicolumn{2}{c|}{test}                               \\ \cline{2-5} 
                                                & \multicolumn{1}{c|}{Accuracy} & \multicolumn{1}{c|}{F1} & \multicolumn{1}{c|}{Accuracy} & \multicolumn{1}{c|}{F1} \\ \hline
        \multicolumn{1}{|l|}{Bi-GRU}            & 0.833, 0.004                  & 0.647, 0.005            & 0.807                         & 0.640                   \\ \hline
        \multicolumn{1}{|l|}{Bi-GRU+Attention}  & 0.837, 0.004                  & 0.655, 0.006            & \textbf{0.811}                         & \textbf{0.648}                   \\ \hline
        \multicolumn{1}{|l|}{CNN}               & 0.821, 0.005                  & 0.649, 0.005            & 0.775                         & 0.637                   \\ \hline
        \multicolumn{1}{|l|}{SVM}               & 0.824, 0.003                  & 0.541, 0.003            & 0.798                         & 0.375                   \\ \hline
        \multicolumn{1}{|l|}{Majority baseline} & -                             & -                       & 0.735                         & 0.282                   \\ \hline
    \end{tabular}
\end{table}

В эксперименте с выборкой, состоящей из наиболее крупных документов - рецензий, предложенный алгоритм превзошёл остальные алгоритмы как на валидации, так и на тестовой подвыборке. Данный результат можно объяснить тем, что рекуррентные нейронные сети имеют свойство терять информацию из середины входной последовательности в случае достаточно длинного входа, и с данной проблемой должна помочь некоторая аггрегация скрытых состояний рекуррентного слоя, что и происходит в механизме внимания.
